{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd7b0fa",
   "metadata": {},
   "source": [
    "### 객체 감지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce36d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import platform\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "weights_path = \"yolov3/yolov3.weights\"\n",
    "config_path = \"yolov3/yolov3.cfg\"\n",
    "names_path = \"yolov3/coco.names\"\n",
    "\n",
    "with open(names_path, \"r\", encoding=\"utf-8\") as coco_file :\n",
    "    label_list = coco_file.read().strip().split('\\n')\n",
    "\n",
    "net = cv2.dnn.readNet(weights_path, config_path)\n",
    "\n",
    "def random_color() :\n",
    "  import random\n",
    "  return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) \n",
    "\n",
    "def get_font() :\n",
    "  import platform\n",
    "  font_size = 20\n",
    "  try:\n",
    "      if platform.system() == \"Windows\":\n",
    "          # 윈도우: 맑은 고딕\n",
    "          return ImageFont.truetype(\"malgun.ttf\", font_size)\n",
    "      elif platform.system() == \"Darwin\":  # macOS\n",
    "          # 맥: 애플 고딕\n",
    "          return ImageFont.truetype(\"AppleGothic.ttf\", font_size)\n",
    "      else:  # Linux 등\n",
    "          # 기본 폰트 (한글 지원 안 될 수 있음)\n",
    "          return ImageFont.load_default(size=font_size)\n",
    "  except IOError:\n",
    "      # 지정한 폰트 파일이 없을 경우 PIL 기본 폰트 사용\n",
    "      return ImageFont.load_default()\n",
    "\n",
    "\n",
    "def detect_objects(image_array) :\n",
    "\n",
    "    image_array = image_array.copy()\n",
    "\n",
    "    image_height, image_width = image_array.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image_array, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    out_layer_list = net.getUnconnectedOutLayersNames()\n",
    "    detection_list = net.forward(out_layer_list)\n",
    "\n",
    "    bounding_box_list = list()\n",
    "    confidence_list = list()\n",
    "    label_index_list = list()\n",
    "\n",
    "    for prediction_list in detection_list :\n",
    "        color = random_color()\n",
    "        for prediction in prediction_list :\n",
    "            bounding_box = prediction[:4] * np.array([image_width, image_height, image_width, image_height])\n",
    "            center_x, center_y, w, h = bounding_box.astype('int')\n",
    "            label_score_list = prediction[5:]\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            label_index = np.argmax(label_score_list)\n",
    "            confidence = label_score_list[label_index]\n",
    "\n",
    "            if confidence > 0 :\n",
    "                bounding_box_list.append([x, y, w ,h])\n",
    "                confidence_list.append(confidence)\n",
    "                label_index_list.append(label_index)\n",
    "\n",
    "    # print(len(bounding_box_list), len(confidence_list), len(label_index_list))\n",
    "\n",
    "    extracted_index_list = cv2.dnn.NMSBoxes(bounding_box_list, confidence_list, 0.7, 0.3)\n",
    "    extracted_index_list\n",
    "\n",
    "    for extracted_index in extracted_index_list :\n",
    "        color = random_color()\n",
    "        x, y, w, h = bounding_box_list[extracted_index]\n",
    "        confidence = confidence_list[extracted_index]\n",
    "        label_index = label_index_list[extracted_index]\n",
    "        label_text = label_list[label_index]\n",
    "\n",
    "        # cv2.rectangle(image_array, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.rectangle(image_array, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # cv2.putText(image_array, f\"{label_text} {confidence:.2f}\", (x, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        cv2.putText(image_array, f\"{label_text} {confidence:.2f}\", (x, y + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "# image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
    "# print(image_array)\n",
    "# Image.fromarray(image_array)\n",
    "# Image.open(BytesIO(image_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141e15f",
   "metadata": {},
   "source": [
    "### dotenv 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811e987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a962ca",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be314660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**감지된 물체 목록 요약:**\\n\\n1. **객체 종류**: 식기\\n   - **감지 확률**: 95%\\n   - **이미지 내 위치**: 테이블 위, 중앙부\\n\\n2. **객체 종류**: 음식 (케이크)\\n   - **감지 확률**: 90%\\n   - **이미지 내 위치**: 테이블 위, 오른쪽 측면\\n\\n3. **객체 종류**: 음료 (와인)\\n   - **감지 확률**: 88%\\n   - **이미지 내 위치**: 테이블 위, 중앙부, 유리잔 형태\\n\\n4. **객체 종류**: 장식 (크리스마스 트리)\\n   - **감지 확률**: 85%\\n   - **이미지 내 위치**: 배경, 왼쪽 상단\\n\\n---\\n\\n**각 물체별 자세한 설명:**\\n\\n1. **식기**\\n   - **특징**: 식기는 다양한 색상과 디자인으로 구성되어 있으며, 일반적으로 음식이 담길 수 있는 평평한 형태를 가집니다. 이 이미지에서는 여러 개의 접시가 보이며, 각 접시는 색상이 다르게 배치되어 있습니다.\\n   - **역할 및 환경 관계**: 식기는 음식 서빙과 소비에 필수적인 요소로, 가족이나 친구들이 함께 모여 식사를 즐길 수 있도록 합니다. 테이블 위에 정갈하게 배치되어 있어, 식사의 준비가 잘 되어 있음을 나타냅니다.\\n\\n2. **음식 (케이크)**\\n   - **특징**: 케이크는 일반적으로 크림으로 덮인 단맛의 디저트로, 여러 층으로 구성될 수 있습니다. 이 이미지에서는 파란색 또는 청록색의 크림으로 장식된 케이크가 보입니다.\\n   - **역할 및 환경 관계**: 케이크는 주로 축하의 자리에서 제공되며, 특별한 날이나 기념일을 기념하기 위해 준비됩니다. 이 장면에서는 가족과 친구들이 모여 축하하는 분위기로, 케이크가 중심적인 역할을 하고 있음을 알 수 있습니다.\\n\\n3. **음료 (와인)**\\n   - **특징**: 와인은 유리잔에 담겨 있으며, 색상은 적색이나 백색이 일반적입니다. 이미지에서는 검은색 유리잔이 보이며, 와인이 담겨 있는 모습이 선명하게 나타나 있습니다.\\n   - **역할 및 환경 관계**: 음료는 식사와 함께 또는 특별한 순간을 기념하기 위해 제공됩니다. 와인은 보통 성숙한 분위기를 연출하며, 사람들 간의 대화와 소통을 촉진하는 역할을 합니다.\\n\\n4. **장식 (크리스마스 트리)**\\n   - **특징**: 크리스마스 트리는 녹색의 나무로, 다양한 장식품과 조명으로 꾸며져 있습니다. 이미지에서는 푸른색의 조명이 장식된 크리스마스 트리가 보입니다.\\n   - **역할 및 환경 관계**: 크리스마스 트리는 연말연시를 기념하는 상징적인 요소로, 가족과 친구들이 함께하는 따뜻한 분위기를 만들어줍니다. 배경에 위치해 있으나 전체적인 장면에 축제의 느낌을 더해주고 있습니다.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import base64\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def request_gpt(image_array) :\n",
    "\n",
    "    image = Image.fromarray(image_array)\n",
    "    byte_image = io.BytesIO()\n",
    "    image.save(byte_image, format='png')\n",
    "    base64_image = base64.b64encode(byte_image.getvalue()).decode('utf-8')\n",
    "\n",
    "    endpoint = openai_endpoint\n",
    "\n",
    "    headers = {\n",
    "        \"Api-Key\" : openai_api_key\n",
    "    }\n",
    "\n",
    "    body = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"\n",
    "                        당신은 YOLO 객체 감지 모델의 분석 결과를 전문적으로 해설하는 AI 분석가입니다.\n",
    "                        제공된 이미지와 함께 전달된 객체 감지 결과(감지 확률, 객체 종류, 위치 등)를 기반으로 하여, 각 감지된 물체에 대해 가장 상세하고 정확하게 설명해야 합니다.\n",
    "                        모든 응답은 한국어로 작성해야 합니다.\n",
    "                        \"\"\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"\"\"\n",
    "                        첨부된 사진은 YOLO 모델을 통해 분석되었으며, 해당 모델이 감지한 **모든 물체**에 대한 정보를 바탕으로 상세 분석 보고서를 작성해 주세요.\n",
    "\n",
    "                        **[요청 사항]**\n",
    "                        1.  **감지된 물체 목록**을 '객체 종류', '감지 확률', '이미지 내 위치(바운딩 박스 좌표/대략적 위치)'를 요약해 주세요.\n",
    "                        2.  **각 물체별로** 다음 내용을 포함하여 **자세한 설명**을 항목별로 추가해 주세요.\n",
    "                            * 물체의 특징 (색상, 상태, 용도 등)\n",
    "                            * 물체의 예상되는 역할 또는 주변 환경과의 관계\n",
    "                        3.  **감지되지 않은 영역이나 배경에 대한 설명은 일체 포함하지 마세요.**\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"max_tokens\": 16384,\n",
    "        \"stop\": None,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(endpoint, headers=headers, json=body)\n",
    "\n",
    "    if response.status_code != 200 :\n",
    "        return None\n",
    "    \n",
    "    response_json = response.json()\n",
    "    content = response_json['choices'][0]['message']['content']\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "TEST_IMAGE_URL = \"https://img.freepik.com/free-photo/close-up-people-preparing-christmas-dinner_23-2149144979.jpg\"\n",
    "response = requests.get(TEST_IMAGE_URL)\n",
    "image_data = response.content\n",
    "image_np = np.frombuffer(image_data, np.uint8)\n",
    "image_array = cv2.imdecode(image_np, cv2.IMREAD_COLOR)\n",
    "\n",
    "request_gpt(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fbf7f",
   "metadata": {},
   "source": [
    "### Speech TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e28474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tts_result_20251212_093223.wav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tts_api_key = os.getenv(\"SPEECH_STUDIO_API_KEY\")\n",
    "tts_endpoint = os.getenv(\"TTS_KR_ENDPOINT\")\n",
    "\n",
    "def request_tts(text) :\n",
    "\n",
    "    endpoint = tts_endpoint\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\" : tts_api_key,\n",
    "        \"Content-Type\" : \"application/ssml+xml\",\n",
    "        \"X-Microsoft-OutputFormat\" : \"audio-16khz-128kbitrate-mono-mp3\"\n",
    "    }\n",
    "\n",
    "    cleaned_text = re.sub(r'[^가-힣a-zA-Z0-9\\s%,\\.]', '', text)\n",
    "\n",
    "    body = f\"\"\"\n",
    "        <speak version='1.0' xml:lang='ko-KR'>\n",
    "            <voice xml:lang='ko-KR' xml:gender='Male' name='ko-KR-InJoonNeural'>\n",
    "                {cleaned_text}\n",
    "            </voice>\n",
    "        </speak>\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, data=body)\n",
    "\n",
    "    if response.status_code != 200 :\n",
    "        return None\n",
    "    \n",
    "    file_name = \"tts_result_{}.wav\".format(datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "    with open(file_name, \"wb\") as audio_file :\n",
    "        audio_file.write(response.content)\n",
    "\n",
    "    return file_name\n",
    "\n",
    "request_tts(\"안녕하세요 만나서 반갑습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd93d76",
   "metadata": {},
   "source": [
    "### Gradio 화면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea84747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EL91\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\EL91\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\components\\image.py:146: UserWarning: The `mirror_webcam` parameter is deprecated. Please use the `webcam_options` parameter with a `gr.WebcamOptions` instance instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo :\n",
    "\n",
    "    def stream_webcam(image_array) :\n",
    "        result_image_array = detect_objects(image_array)\n",
    "        return result_image_array\n",
    "    \n",
    "    def click_capture(image_array) :\n",
    "        if image_array is None :\n",
    "            return gr.Error(\"감지된 이미지가 없습니다.\", duration=3)\n",
    "        return image_array\n",
    "    \n",
    "    def click_send_gpt(image_array, histories) :\n",
    "\n",
    "        content = request_gpt(image_array)\n",
    "        label_text = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "        histories.append({\n",
    "            \"role\" : \"user\", \"content\" : gr.Image(label=label_text, value=image_array)\n",
    "        })\n",
    "        histories.append({\n",
    "            \"role\" : \"assistant\", \"content\" : content\n",
    "        })\n",
    "\n",
    "        return histories\n",
    "\n",
    "    def change_chatbot(histories) :\n",
    "        content = histories[-1]['content']\n",
    "        file_name =  request_tts(content)\n",
    "        return file_name\n",
    "\n",
    "\n",
    "    with gr.Row() :\n",
    "        webcam_image = gr.Image(label=\"실시간 화면\", sources=\"webcam\", mirror_webcam=False)\n",
    "        output_image = gr.Image(label=\"감지 화면\", interactive=False)\n",
    "        capture_image = gr.Image(label=\"이상 징후 발생 화면\", interactive=False)\n",
    "    \n",
    "    with gr.Row() :\n",
    "        capture_button = gr.Button(\"이상 징후 발생\")\n",
    "        send_gpt_button = gr.Button(\"분석\", )\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"분석결과\", type=\"messages\", height=720)\n",
    "    chatbot_audio = gr.Audio(label=\"분석 결과\", interactive=False, autoplay=True)\n",
    "\n",
    "    webcam_image.stream(stream_webcam, inputs=[webcam_image], outputs=[output_image])\n",
    "    capture_button.click(click_capture, inputs=[output_image], outputs=[capture_image])\n",
    "    send_gpt_button.click(click_send_gpt, inputs=[capture_image, chatbot], outputs=[chatbot])\n",
    "    chatbot.change(change_chatbot, inputs=[chatbot], outputs=[chatbot_audio])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
